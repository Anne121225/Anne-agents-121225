
Regulatory Intelligence Report: AI Integration in Premarket Submission Reviews (FDA & Swissmedic)
Date: December 2025
Subject: Comparative Analysis of Artificial Intelligence Integration in Regulatory Review Processes (2020–2025)
Agencies Reviewed: U.S. Food and Drug Administration (FDA) & Swissmedic
Scope: Premarket Submissions for Drugs, Biologics, and Medical Devices

Executive Summary
As of late 2025, the global regulatory landscape for medical products has undergone a paradigm shift driven by the integration of Artificial Intelligence (AI) and Machine Learning (ML). The geometric increase in data volume associated with New Drug Applications (NDAs), Biologics License Applications (BLAs), and medical device 510(k) submissions rendered traditional, purely human-led review processes unsustainable.

This report provides an in-depth analysis of how two leading regulatory bodies—the U.S. FDA and the Swiss Agency for Therapeutic Products (Swissmedic)—have adapted to this reality. While both agencies share the ultimate goal of patient safety and market efficiency, their operational strategies diverge significantly. The FDA has adopted an aggressive, tool-centric approach, culminating in the 2025 deployment of "Project Elsa," an agentic AI system designed to automate triage and scientific review. Conversely, Swissmedic has pursued a framework-centric strategy, emphasizing international harmonization via the International Medical Device Regulators Forum (IMDRF) and rigorous assessment of applicant data without reliance on proprietary, internal autonomous AI tools.

This document details the evolution, technical implementation, regulatory impact, and future challenges of these distinct approaches, extending from early pilot programs to the agency-wide deployments witnessed in mid-2025.

1. Introduction: The Imperative for AI in Regulation

1.1 The Data Deluge
By the early 2020s, the complexity of medical product submissions had escalated. A standard NDA could easily exceed 500,000 pages of clinical data, manufacturing specifications, and stability studies. For medical devices, the rise of Software as a Medical Device (SaMD) introduced code-based complexities that traditional paper-based review paradigms struggled to address.

Regulatory agencies faced a "data deluge" that threatened to extend review timelines, delay life-saving therapies, and burn out specialized staff. The integration of AI became not merely an innovation but an operational necessity.

1.2 Defining the Scope
This report focuses on two distinct applications of AI in the regulatory sphere:

AI in the Product: How agencies regulate medical devices and drugs that incorporate AI/ML (e.g., algorithms for diagnosis).
AI for the Regulator: How agencies use AI tools internally to review submissions, triage data, and detect patterns.
While the FDA has aggressively pursued the latter to manage the former, Swissmedic has focused heavily on creating robust frameworks to evaluate the former, while maintaining a human-centric approach to the latter.

2. FDA AI Evolution: From Pilots to Agentic AI
The FDA’s journey toward AI integration has been characterized by iterative piloting, starting with simple data processing automation and evolving into "Project Elsa," a sophisticated agentic AI ecosystem.

2.1 Early Explorations and The Scientific Review Pilot
The FDA began exploring AI to counter rising submission volumes and concurrent staff reductions. Initial efforts focused on Natural Language Processing (NLP) to digitize and index legacy documents.

By early 2024, the FDA launched the AI-Assisted Scientific Review Pilot. This program was designed to test whether Large Language Models (LLMs) could assist reviewers in cross-referencing data across disparate sections of an application.

Objective: Enable broader data comparison across applications for drugs, biologics, and devices.
Outcome: By May 2025, the pilot was deemed a success. It demonstrated that AI could provide reviewers with "broader perspectives" on preclinical and clinical data patterns that might be missed during a segmented human review.
Impact: The success of this pilot was the green light for agency-wide deployment, directly countering review delays caused by staffing shortages.
2.2 Project Elsa: The 2025 Deployment
In June 2025, following the success of the pilots, the FDA announced a radical shift in its operational model. FDA Commissioner Martin Makary unveiled "Project Elsa," an agentic AI system.

Unlike standard generative AI (which produces text), Agentic AI possesses the capability to execute multi-step workflows. Project Elsa was not designed to replace the final decision-maker but to act as a highly capable executive assistant.

Table 1: Capabilities of FDA's Project Elsa (2025)
Functional Domain	Specific Tasks Executed by Elsa	Human Oversight Protocol
Premarket Review	Summarizing toxicity studies; checking formatting compliance; cross-referencing claimed side effects with raw clinical data.	Reviewers must validate every AI-generated summary against source documents.
Triage & Validation	Sorting incoming 510(k) submissions; validating administrative completeness; prioritizing inspections based on risk flags.	"Human-in-the-loop" mandatory before rejection or acceptance of filing.
Pharmacovigilance	Automating literature reviews for adverse events; detecting signals in post-market surveillance data.	Epidemiologists review flagged signals for causality assessment.
Medical Writing	Drafting initial sections of the review memo; standardizing language for denial/approval letters.	Final signature and legal responsibility remain with the Division Director.
Data Analysis	Processing up to 500,000 pages to extract key efficacy endpoints.	Statistical analysis plans are pre-verified by human biostatisticians.
2.3 The Strategic Shift to Efficiency
The June 2025 announcement emphasized "radically increasing efficiency." With the ability to process half a million pages, Elsa addresses the sheer volume bottleneck. By November 2025, the system was expanded to cover review validation and post-market surveillance, creating a closed-loop data ecosystem where premarket data informs post-market monitoring and vice versa.

2.4 Managing AI-Enabled Devices: The PCCP Framework
Parallel to using AI for reviews, the FDA revolutionized how it reviews AI products. The Predetermined Change Control Plan (PCCP) guidance, finalized in 2024, allows manufacturers to specify how their AI models will evolve post-market.

The Mechanism: If a manufacturer details future algorithm retrainings in the PCCP and the FDA approves it, they can update the device without a new 510(k) submission.
The Result: This removed a massive administrative burden for continuous-learning algorithms, facilitating the clearance of over 1,200 AI/ML devices by mid-2025.
3. Swissmedic Framework: Quality, Harmonization, and Supervision
Swissmedic operates under a different set of constraints and philosophies compared to the FDA. As a smaller agency deeply integrated into the European economic sphere (though politically distinct), it prioritizes high-quality assessment frameworks and international interoperability over the development of proprietary internal AI tools.

3.1 The "Smart Regulator" Philosophy
Swissmedic views AI/ML as vital for drug development—specifically in molecule identification and clinical trial design—but maintains a cautious stance on the "black box" nature of these technologies.

By 2025, no specific domestic AI review tool (equivalent to Elsa) had emerged within Swissmedic. Instead, the agency focused on:

Digital Transformation: Moving to a fully digital submission platform.
SwissDaMed: A medical device database for surveillance and transparency.
Human Expertise: Relying on highly specialized reviewers to assess AI-generated elements in submissions.
3.2 Evaluation Criteria
Swissmedic evaluates AI in submissions based on whether the data is "complete, state-of-the-art, and transparent."

Transparency: Can the applicant explain how the AI arrived at a conclusion?
Bias: Has the training data been vetted for demographic or geographic bias?
Data Quality: adhering to ALCOA+ principles (Attributable, Legible, Concurrent, Original, Accurate).
3.3 International Harmonization as a Strategy
Swissmedic leverages its status as a WHO Listed Authority and an observer in the IMDRF to align its requirements with global standards.

IMDRF Contribution: Swissmedic actively drafts guidelines in AI/ML working groups, focusing on Good Regulatory Review Practices.
Standard Adoption: They assess submissions using guidelines from ICH (International Council for Harmonisation), FDA, and EMA. This prevents Switzerland from becoming a "regulatory island" and ensures that Swiss patients have access to global innovations.
3.4 Lifecycle Supervision
Unlike the FDA's PCCP which pre-authorizes change, Swissmedic emphasizes "Lifecycle Supervision." This involves rigorous post-market surveillance via the SwissDaMed database to monitor the performance of AI devices in the real world, ensuring that "software decay" or "model drift" does not compromise patient safety.

4. Comparative Analysis: FDA vs. Swissmedic
The divergence in 2025 approaches can be attributed to scale, resources, and regulatory philosophy.

4.1 Comparison of Operational Models

Table 2: Operational Comparison (FDA vs. Swissmedic 2025)
Aspect	FDA (United States)	Swissmedic (Switzerland)
Primary AI Strategy	Tool-Creation: Developing internal agents (Elsa) to automate the review workflow.	Framework-Adoption: Establishing rigorous standards for assessing external AI.
Review Automation	High. Agentic AI handles triage, summaries, and drafting.	Low. Human reviewers rely on digital workflows but manual intellectual assessment.
Device Regulation	PCCP (2024): Pre-approval of future changes to reduce submission volume.	Lifecycle Supervision: Continuous monitoring via SwissDaMed; changes often require notification.
International Role	Leader: Exports standards (like PCCP concepts) to IMDRF.	Harmonizer: Adopts and refines global standards (IMDRF, ICH) for local context.
Resource Allocation	Massive investment in IT infrastructure and proprietary model training.	Investment in interoperable databases (SwissDaMed) and staff training on global guidelines.
Risk Appetite	Higher. Willing to use "Black Box" AI (Elsa) with human oversight to gain efficiency.	Lower. Prioritizes transparency and explainability; cautious of "automation bias."
4.2 The "Human-in-the-Loop" Variance
Both agencies mandate human oversight, but the application differs:

FDA: The human acts as a Validator. The AI does the work; the human checks it. This is necessary due to the volume of 500,000-page applications.
Swissmedic: The human acts as the Evaluator. The human does the work, supported by digital tools. The lower volume of submissions in Switzerland allows for this more granular, hands-on approach.
5. Key Tools and Pathways in 2025

5.1 FDA Device Clearance Landscape
By mid-2025, the FDA had cleared over 1,200 AI/ML-enabled devices. The pathways used reveal the maturity of the technology.

Table 3: FDA AI/ML Device Clearance Pathways (2025 Data)
Pathway	Percentage of AI Devices	Description	Typical Use Case
510(k)	~96%	Substantial equivalence to a predicate device.	Radiology algorithms, cardiac monitoring software.
De Novo	~3-4%	Novel devices with low-to-moderate risk (no predicate).	First-of-kind diagnostic AIs (e.g., diabetic retinopathy screening without a doctor).
PMA (Premarket Approval)	~0.4%	High-risk devices requiring rigorous clinical trials.	Closed-loop AI delivering therapy (e.g., autonomous insulin pumps).
5.2 SwissDaMed
SwissDaMed represents the core of Swissmedic’s digital infrastructure. It is a cloud-based registry that ensures:

Traceability: Every device in the Swiss market is registered.
Surveillance: It integrates with vigilance reporting systems to flag AI errors.
Transparency: Accessible to stakeholders to verify device status.
5.3 Good Machine Learning Practice (GMLP)
Both agencies align on the IMDRF N88 (GMLP) principles, finalized in 2025. These 10 principles guide both the development of devices and the review of those devices.

Table 4: Key GMLP Principles Adopted by FDA and Swissmedic
Principle	Description	Implementation Focus
1. Multi-Disciplinary Expertise	Teams must include clinicians, data scientists, and engineers.	FDA: Integrated into Project Elsa teams. <br>Swissmedic: Requirement for applicants.
2. Good Software Engineering	Code hygiene, version control, and modularity.	Swissmedic: Key part of technical documentation review.
3. Representative Data	Training data must match the target population (age, sex, ethnicity).	FDA: Major focus of Scientific Review Pilot to detect bias.
4. Separation of Data	Strict separation between Training, Tuning, and Testing sets.	Both: "Data leakage" is a primary reason for rejection.
5. Performance Focus	Metrics must reflect clinical reality (not just AUC, but sensitivity/specificity).	FDA: PCCP requires pre-defined performance metrics for future updates.
6. Challenges and Future Risks

6.1 Agentic AI Risks (FDA Focus)
The deployment of Project Elsa introduces "Automation Bias." If Elsa summarizes a 500-page toxicology report and misses a nuance, the human reviewer—under time pressure—might accept the summary as truth.

Mitigation: The FDA has implemented strict "validation protocols" where reviewers must cite the page number of the source document that supports the AI's summary.
6.2 Transparency and Bias (Joint Focus)
Both agencies struggle with the "Black Box" problem. Deep Learning models often cannot explain why they detected a tumor.

Swiss Approach: Swissmedic emphasizes "explainability" in its guidelines. If the AI cannot explain the result, the clinical validation data must be overwhelmingly strong.
FDA Approach: The FDA focuses on "performance monitoring." If the "Black Box" works consistently across diverse populations, it is accepted, provided a PCCP is in place to monitor drift.
6.3 Workforce Impact
The prompt notes FDA "staff reductions." The 2025 rollout of Elsa was partly a response to this. While AI covers the volume gap, it creates a need for a new type of employee: the "AI-Literate Reviewer." Both agencies face a shortage of staff who understand both regulatory law and data science.

Table 5: 2025 Strategic Risks Assessment
Risk Category	FDA (Project Elsa Context)	Swissmedic (Framework Context)
Algorithmic Bias	High Risk. If Elsa is trained on biased historical review data, it may perpetuate inconsistent decision-making.	Medium Risk. Reliance on external guidelines minimizes internal bias, but reviewing applicant bias remains hard.
Data Security	Critical. Elsa processes proprietary pharma data. A breach would be catastrophic.	High. SwissDaMed is a target, but holds less proprietary IP than FDA review systems.
Regulatory Capture	Medium. Over-reliance on AI metrics provided by industry might obscure clinical reality.	Low. Conservative review culture acts as a buffer.
Operational Continuity	High. What happens if Elsa goes offline? Staff atrophy may lead to inability to review manually.	Low. Manual processes remain the core competency.
7. Conclusion
By late 2025, the FDA and Swissmedic have demonstrated two viable but distinct paths for AI in regulation. The FDA has positioned itself as a "Digital Pioneer," absorbing the risks of developing and deploying agentic AI (Project Elsa) to solve the crisis of volume and efficiency. This has allowed for rapid processing of 500,000-page applications and the seamless clearance of 1,200+ AI devices.

Swissmedic, conversely, has established itself as a "Quality Guardian," leveraging international alliances (IMDRF, WHO) to maintain rigorous standards without the capital-intensive development of internal AI agents.

As the industry moves toward 2026, the convergence of these paths seems inevitable. Swissmedic will likely adopt tools similar to Elsa once they are commoditized and proven safe, while the FDA will likely refine its agentic workflows based on the "safety-first" principles championed by Swiss and European regulators. The era of AI in regulation is no longer a pilot project; it is the operating standard.

8. Appendices

8.1 Glossary of Key Entities (20 Entities with Context)
Project Elsa: FDA's 2025 agentic AI tool designed for premarket triage, literature review, and case prioritization, functioning with mandatory human validation.
AI-Assisted Pilot: A pivotal FDA program completed in May 2025 that validated the use of AI for scientific review of submissions, specifically for data pattern analysis across applications.
Predetermined Change Control Plan (PCCP): A 2024 FDA guidance allowing medical device manufacturers to pre-specify future algorithm modifications, enabling updates without new 510(k) submissions.
510(k) Pathway: The primary regulatory route for over 96% of FDA AI/ML device clearances by 2025, relying on demonstrating substantial equivalence to predicates.
Generative AI Rollout: The FDA’s strategic plan for agency-wide deployment of generative AI tools by June 30, 2025, across all major centers (CDER, CBER, CDRH).
Swissmedic AI Framework: A set of 2022 guidelines used by Swiss regulators to assess AI elements in submissions, referencing ICH, IMDRF, and FDA standards.
IMDRF GMLP (N88): The 2025 "Good Machine Learning Practice" principles focusing on transparency, bias reduction, and data management; Swissmedic is a key contributor.
SwissDaMed Database: Swissmedic's centralized, cloud-based medical device registry used for market surveillance and ensuring stakeholder transparency.
Agentic AI: An advanced form of AI offering autonomous multistep workflow capabilities, deployed by the FDA in 2025 for reviews and administrative tasks with strict oversight.
Martin Makary: The FDA Commissioner (as of the reporting period) who announced the 2025 AI expansions and the launch of Project Elsa.
Good Regulatory Review Practices: An IMDRF working group where Swissmedic actively contributes to defining standards for reviewing AI/ML technologies.
Software as Medical Device (SaMD): A primary focus area within IMDRF that guides Swissmedic's assessment of standalone AI software.
ICH Guidelines: International Council for Harmonisation standards (e.g., M10, Q9) utilized by Swissmedic to validate AI-generated data in drug submissions.
Premarket Approval (PMA): The most stringent FDA pathway, used for roughly 0.4% of high-risk AI devices (Class III) requiring clinical trials.
De Novo Pathway: The FDA regulatory route for novel Class I or II AI devices that have no existing predicate, accounting for ~3-4% of clearances.
RFIA Requests: "Request for Information/Additional" – queries sent by Swissmedic during device reviews, often focusing on AI data transparency.
WHO Listed Authority: Swissmedic's status (confirmed 2024-2025) which facilitates global alignment and reliance on its decisions by other nations.
AI/ML Device List: An FDA public tracker documenting the exponential growth of AI devices from 6 in 2015 to over 1,200 by mid-2025.
Lifecycle Supervision: The Swissmedic regulatory philosophy that emphasizes continuous post-market monitoring of AI products rather than just pre-market clearance.
Bias and Transparency: The two core ethical and technical challenges that both agencies prioritize in their review of AI models to prevent patient harm.
8.2 Follow-Up Questions for Further Analysis
How does FDA's Elsa specifically handle the token limits and context windows when processing 500,000-page submissions in practice?
What specific quantitative metrics (e.g., reduction in review hours) showed success in FDA's 2025 AI pilot completion?
Compare the safety outcomes of AI devices cleared via PCCP versus those cleared via traditional 510(k) resubmissions post-2024.
Has Swissmedic piloted any internal AI tools for administrative tasks (HR, finance) even if not for review by late 2025?
Detail the specific implementation differences of IMDRF's 10 GMLP principles between the US and Switzerland.
What were the cultural and morale impacts on FDA staff resulting from the 2025 AI rollout coinciding with layoffs?
How does SwissDaMed technically integrate with hospital systems to use AI for automated market surveillance signals?
Analyze the approval rates of 510(k) vs. PMA for AI devices in 2025—is the PMA pathway becoming obsolete for software?
What specific examples of algorithmic biases have FDA reviewers identified and rejected using AI-assisted tools?
How does Swissmedic's WHO Listed Authority status specifically facilitate the export of Swiss medical devices to emerging markets?
Does Project Elsa have write-access to the FDA's decision databases, or is it strictly read-only with draft capabilities?
What specific clauses did Swissmedic contribute to the IMDRF AI working groups regarding "human-in-the-loop" requirements since 2022?
What are the FDA's specific plans for using AI in the review of biologics (CBER) distinct from small molecule drugs (CDER)?
What are the technical challenges in "validating" the output of Agentic AI—how do you benchmark a nondeterministic output?
How does Swissmedic assess AI used in "adaptive clinical trial designs" where the trial parameters change based on live data?
Based on 2025 data, what are the growth projections for AI/ML device approvals in 2026 and 2027?
Are there noticeable differences in the acceptance of "Black Box" algorithms between FDA and EMA, and how does Swissmedic position itself between them?
What are the specific protocols for human oversight in Swissmedic's guideline assessments—is there a "four-eyes" principle?
What are the economic impacts of AI on review timelines—have application fees dropped, or has time-to-market decreased?
Are there legislative proposals in the Swiss parliament to create a dedicated "AI and Digital Health Authority" separate from Swissmedic?
References
[1] King & Spalding. "FDA Announces Completion of AI-Assisted Scientific Review Pilot and Deployment of Agency-Wide AI-Assisted Review." King & Spalding Insights, 2025.
[2] Swissmedic. "Artificial Intelligence and Machine Learning in Medical Devices." Swissmedic Home, 2025.
[3] New York Times. "FDA Drug Approvals and Artificial Intelligence: A New Era." NYT Health, June 10, 2025.
[4] StatNews. "FDA Announces Agentic AI 'Elsa' for Pre-Market Review." StatNews, December 1, 2025.
[5] Hogan Lovells. "FDA Advances AI-Powered Review of Medical Product Applications." Hogan Lovells Publications, 2025.
[6] PharmaLex. "What Project Elsa Means for the FDA's Approach to AI." PharmaLex Thought Leadership, 2025.
[7] American Hospital Association. "FDA Finalizes Recommendations Simplifying Approval Process for Medical Devices Using AI." AHA News, December 5, 2024.
[8] Intuition Labs. "FDA AI Medical Device Tracker: 2015-2025." Intuition Labs Articles, 2025.
[9] IMDRF. "Switzerland (Swissmedic) Regulatory Update: AI/ML." IMDRF Documents, October 2024.
[10] Swissmedic. "Review of Current and Future Challenges: Regulatory 2024." Swissmedic Publications, 2024.
[11] Pure Clinical. "MHRA & IMDRF's Latest Guidance on AI and Medical Device Software." Pure Clinical News, 2025.
[12] Emergo by UL. "IMDRF Releases Key Guidance Documents on Medical Device Software." Emergo News, 2025.
[13] Decomplix. "Medical Device Compliance in Switzerland." Decomplix Insights, 2025.
[14] Swissmedic. "Human Medicines Authorisation." Swissmedic, 2025.
[15] FDA. "Guidance for Industry: PCCPs." FDA Media, 2024.
[16] Sidley Austin. "New Pathway of Regulating Artificial Intelligence in Switzerland." Sidley Insights, March 2025.
