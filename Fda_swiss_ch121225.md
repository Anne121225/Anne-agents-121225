監管情報報告：上市前提交審查中的 AI 整合（FDA 與 Swissmedic）
日期： 2025 年 12 月
主題： 監管審查流程中人工智慧整合的比較分析（2020–2025）
審查機構： 美國食品藥物管理局（FDA）與 瑞士醫藥管理局（Swissmedic）
範圍： 藥品、生物製劑及醫療器材的上市前提交（Premarket Submissions）

執行摘要 (Executive Summary)
截至 2025 年底，全球醫療產品的監管格局因人工智慧（AI）與機器學習（ML）的整合而發生了典範轉移。伴隨新藥查驗登記（NDA）、生物製劑許可申請（BLA）及醫療器材 510(k) 提交而來的數據量呈幾何級數增長，使得傳統純依賴人力的審查模式難以為繼。

本報告深入分析了兩個主要監管機構——美國 FDA 與瑞士 Swissmedic——如何適應這一現實。儘管雙方的最終目標皆為病患安全與市場效率，但其運作策略卻有顯著差異。FDA 採取了積極的「工具導向」方法，最終於 2025 年部署了「Elsa 計畫（Project Elsa）」，這是一個旨在自動化分流與科學審查的代理型 AI（Agentic AI）系統。相反地，Swissmedic 採取了「框架導向」策略，強調透過國際醫療器材法規監管論壇（IMDRF）進行國際協調，並嚴格評估申請人的數據，而非依賴內部的專有自主 AI 工具。

本文件詳細闡述了這些不同方法的演變、技術實施、監管影響及未來挑戰，涵蓋了從早期試點計畫到 2025 年中期全面部署的過程。

1. 前言：監管中引入 AI 的必要性

1.1 數據洪流 (The Data Deluge)
到了 2020 年代初期，醫療產品提交的複雜性急劇上升。一份標準的 NDA 可能輕易超過 50 萬頁，包含臨床數據、製造規範及安定性試驗資料。對於醫療器材而言，軟體即醫療器材（SaMD）的興起引入了代碼層面的複雜性，這是傳統紙本審查範式難以應對的。

監管機構面臨著「數據洪流」，這不僅威脅到審查時程的延長，可能延誤救命療法的推出，更加劇了專業人員的職業倦怠。AI 的整合不僅僅是一種創新，更成為了運作上的必要條件。

1.2 定義範圍
本報告聚焦於監管領域中 AI 的兩類不同應用：

產品中的 AI（AI in the Product）： 機構如何監管包含 AI/ML 的醫療器材與藥品（例如：用於診斷的演算法）。
監管者的 AI（AI for the Regulator）： 機構內部如何使用 AI 工具來審查提交文件、分流數據及檢測模式。
雖然 FDA 積極追求後者以管理前者，但 Swissmedic 則將重點放在建立強大的框架來評估前者，同時在內部審查流程中維持以人為本的方法。

2. FDA 的 AI 演變：從試點到代理型 AI
FDA 的 AI 整合之旅以反覆的試點為特徵，從簡單的數據處理自動化開始，發展成為「Elsa 計畫」這一複雜的代理型 AI 生態系統。

2.1 早期探索與科學審查試點
FDA 最初開始探索 AI 是為了應對不斷增加的提交量及同時發生的人員縮減。最初的努力集中於自然語言處理（NLP），以將舊文件數位化並建立索引。

到了 2024 年初，FDA 啟動了AI 輔助科學審查試點（AI-Assisted Scientific Review Pilot）。該計畫旨在測試大型語言模型（LLM）是否能協助審查人員交叉比對申請文件中不同章節的數據。

目標： 實現藥品、生物製劑及器材申請中更廣泛的數據比對。
結果： 到 2025 年 5 月，該試點被視為成功。它證明了 AI 能為審查人員提供關於臨床前與臨床數據模式的「更廣闊視角」，這些模式在分段的人工審查中可能會被忽略。
影響： 此試點的成功為全機構的部署亮起了綠燈，直接緩解了因人員短缺造成的審查延誤。
2.2 Elsa 計畫：2025 年的部署
2025 年 6 月，繼試點成功後，FDA 宣布其運作模式的重大轉變。FDA 局長 Martin Makary 揭示了「Elsa 計畫（Project Elsa）」，這是一個代理型 AI 系統。

與標準的生成式 AI（僅生成文本）不同，代理型 AI（Agentic AI） 具備執行多步驟工作流程的能力。Elsa 計畫的設計並非為了取代最終決策者，而是作為一位能力極強的執行助理。

表 1：FDA Elsa 計畫的功能能力 (2025)
功能領域	Elsa 執行的具體任務	人類監督協議
上市前審查	總結毒性研究；檢查格式合規性；將聲稱的副作用與原始臨床數據進行交叉比對。	審查人員必須針對原始文件驗證每一個 AI 生成的摘要。
分流與驗證	對傳入的 510(k) 提交進行分類；驗證行政完整性；根據風險標記優先安排查廠。	在拒絕或接受歸檔前，強制執行「人在迴路（Human-in-the-loop）」機制。
藥物警戒	自動化不良事件的文獻回顧；在上市後監測數據中檢測訊號。	流行病學家審查被標記的訊號以進行因果關係評估。
醫學寫作	起草審查備忘錄的初始章節；標準化核准/拒絕信函的用語。	最終簽名與法律責任仍歸屬於部門主管。
數據分析	處理高達 50 萬頁的文件以提取關鍵療效指標。	統計分析計畫需由人類生物統計學家預先驗證。
2.3 轉向效率的策略
2025 年 6 月的公告強調「從根本上提高效率」。憑藉處理五十萬頁文件的能力，Elsa 解決了巨大的數量瓶頸。到了 2025 年 11 月，該系統擴展至涵蓋審查驗證與上市後監測，建立了一個閉環數據生態系統，使上市前數據能為上市後監控提供資訊，反之亦然。

2.4 管理 AI 賦能器材：PCCP 框架
在利用 AI 進行審查的同時，FDA 也徹底改革了其審查 AI 產品的方式。2024 年定案的**預定變更控制計畫（Predetermined Change Control Plan, PCCP）**指引，允許製造商說明其 AI 模型在上市後將如何演變。

機制： 如果製造商在 PCCP 中詳細說明未來的演算法重新訓練計畫並獲得 FDA 核准，他們可以在不需重新提交 510(k) 的情況下更新器材。
結果： 這消除了持續學習演算法的巨大行政負擔，促成了 2025 年中期超過 1,200 項 AI/ML 器材的獲准。
3. Swissmedic 框架：品質、協調與監管
與 FDA 相比，Swissmedic 在不同的限制與理念下運作。作為一個深度融入歐洲經濟圈（雖政治上獨立）的較小型機構，它優先考慮高品質的評估框架與國際互操作性，而非開發內部的專有 AI 工具。

3.1 「智慧監管者」理念
Swissmedic 視 AI/ML 為藥物開發的關鍵——特別是在分子識別與臨床試驗設計方面——但對這些技術的「黑盒子」性質保持謹慎態度。

截至 2025 年，Swissmedic 內部尚未出現特定的 AI 審查工具（相當於 Elsa）。相反，該機構專注於：

數位轉型： 轉移至全數位化提交平台。
SwissDaMed： 用於監測與透明化的醫療器材資料庫。
人類專業： 依靠高度專業化的審查人員來評估提交文件中的 AI 生成元素。
3.2 評估標準
Swissmedic 根據數據是否「完整、最先進（state-of-the-art）且透明」來評估提交中的 AI。

透明度： 申請人能否解釋 AI 如何得出結論？
偏差： 訓練數據是否已針對人口統計或地理偏差進行審查？
數據品質： 遵守 ALCOA+ 原則（可歸屬、清晰、同步、原始、準確）。
3.3 國際協調策略
Swissmedic 利用其作為**WHO 列名監管機構（WHO Listed Authority）**及 IMDRF 觀察員的地位，使其要求與全球標準保持一致。

IMDRF 貢獻： Swissmedic 積極在 AI/ML 工作組中起草指引，專注於優良監管審查規範。
標準採用： 他們使用 ICH（國際醫藥法規協和會）、FDA 和 EMA 的指引來評估提交。這避免了瑞士成為「監管孤島」，並確保瑞士病患能獲得全球創新產品。
3.4 全生命週期監管
與 FDA 預先授權變更的 PCCP 不同，Swissmedic 強調「全生命週期監管（Lifecycle Supervision）」。這涉及透過 SwissDaMed 資料庫進行嚴格的上市後監測，以監控 AI 器材在真實世界中的表現，確保「軟體衰退」或「模型漂移」不會損害病患安全。

4. 比較分析：FDA 與 Swissmedic
2025 年兩者方法的差異可歸因於規模、資源與監管理念。

4.1 運作模式比較

表 2：運作比較（FDA vs. Swissmedic 2025）
面向	FDA（美國）	Swissmedic（瑞士）
主要 AI 策略	工具創造： 開發內部代理（Elsa）以自動化審查工作流程。	框架採用： 建立嚴格標準以評估外部 AI。
審查自動化	高。代理型 AI 處理分流、摘要與草擬。	低。審查人員依賴數位工作流程，但進行人工智力評估。
器材監管	PCCP (2024)： 預先核准未來變更以減少提交量。	全生命週期監管： 透過 SwissDaMed 持續監控；變更通常需要通報。
國際角色	領導者： 輸出標準（如 PCCP 概念）至 IMDRF。	協調者： 採用並改進全球標準（IMDRF, ICH）以適應在地情境。
資源配置	對 IT 基礎設施與專有模型訓練進行巨額投資。	投資於互操作資料庫（SwissDaMed）與員工全球指引培訓。
風險偏好	較高。願意在有人類監督下使用「黑盒子」AI（Elsa）以換取效率。	較低。優先考慮透明度與可解釋性；對「自動化偏誤」保持謹慎。
4.2 「人在迴路」的差異
雙方機構皆強制要求人類監督，但應用方式不同：

FDA： 人類扮演驗證者（Validator）。AI 執行工作；人類進行檢查。這是由於 50 萬頁申請文件的數量所致。
Swissmedic： 人類扮演評估者（Evaluator）。人類在數位工具輔助下執行工作。瑞士較低的提交量允許這種更細緻、親力親為的方法。
5. 2025 年的關鍵工具與途徑

5.1 FDA 器材獲准概況
截至 2025 年中期，FDA 已核准超過 1,200 項 AI/ML 賦能器材。所使用的途徑揭示了技術的成熟度。

表 3：FDA AI/ML 器材獲准途徑（2025 年數據）
途徑	AI 器材佔比	描述	典型應用案例
510(k)	~96%	與對照器材（Predicate）具有實質等同性。	放射科演算法、心臟監測軟體。
De Novo	~3-4%	低至中度風險的創新器材（無對照品）。	首創的診斷 AI（例如：無需醫師參與的糖尿病視網膜病變篩檢）。
PMA (上市前核准)	~0.4%	需要嚴格臨床試驗的高風險器材。	提供治療的閉環 AI（例如：自動胰島素幫浦）。
5.2 SwissDaMed
SwissDaMed 代表了 Swissmedic 數位基礎設施的核心。它是一個雲端註冊系統，確保：

可追溯性： 瑞士市場上的每台器材皆已註冊。
監測： 整合警戒通報系統以標記 AI 錯誤。
透明度： 利益相關者可訪問以查驗器材狀態。
5.3 優良機器學習規範 (GMLP)
雙方機構皆與 IMDRF N88 (GMLP) 原則保持一致，該原則於 2025 年定案。這 10 項原則指導了器材的開發與審查。

表 4：FDA 與 Swissmedic 採用的關鍵 GMLP 原則
原則	描述	實施重點
1. 多學科專業知識	團隊必須包含臨床醫師、數據科學家與工程師。	FDA： 整合進 Elsa 計畫團隊。<br>Swissmedic： 對申請人的要求。
2. 優良軟體工程	程式碼衛生、版本控制與模組化。	Swissmedic： 技術文件審查的關鍵部分。
3. 具代表性的數據	訓練數據必須符合目標族群（年齡、性別、種族）。	FDA： 科學審查試點檢測偏差的主要重點。
4. 數據分離	嚴格區分訓練集、調整集與測試集。	雙方： 「數據洩漏」是拒絕申請的主要原因。
5. 績效導向	指標必須反映臨床現實（不只是 AUC，還包括敏感度/特異度）。	FDA： PCCP 要求為未來更新預先定義績效指標。
6. 挑戰與未來風險

6.1 代理型 AI 風險（FDA 重點）
部署 Elsa 計畫 引入了「自動化偏誤」。如果 Elsa 總結一份 500 頁的毒理學報告時遺漏了一個細微差別，在時間壓力下的人類審查員可能會將摘要視為事實。

緩解措施： FDA 實施了嚴格的「驗證協議」，審查員必須引用支持 AI 摘要的原始文件頁碼。
6.2 透明度與偏差（共同重點）
雙方機構皆面臨「黑盒子」問題。深度學習模型往往無法解釋為什麼檢測到了腫瘤。

瑞士方法： Swissmedic 在指引中強調「可解釋性」。如果 AI 無法解釋結果，臨床驗證數據必須具有壓倒性的強度。
FDA 方法： FDA 專注於「績效監控」。如果「黑盒子」在不同族群中運作一致，且有 PCCP 監控漂移，則可被接受。
6.3 勞動力影響
提示中指出 FDA 面臨「人員縮減」。Elsa 在 2025 年的推出部分是為了回應這一點。雖然 AI 填補了數量缺口，但它創造了對新型員工的需求：「具 AI 素養的審查員」。雙方機構都面臨既懂監管法律又懂數據科學的人才短缺。

表 5：2025 年策略風險評估
風險類別	FDA（Elsa 計畫情境）	Swissmedic（框架情境）
演算法偏差	高風險。 如果 Elsa 接受有偏差的歷史審查數據訓練，可能會延續不一致的決策。	中風險。 依賴外部指引可最小化內部偏差，但審查申請人的偏差仍然困難。
數據安全	關鍵。 Elsa 處理專有的藥廠數據。外洩將是災難性的。	高。 SwissDaMed 是一個目標，但持有的專有 IP 少於 FDA 審查系統。
監管俘虜	中等。 過度依賴產業界提供的 AI 指標可能會模糊臨床現實。	低。 保守的審查文化起到緩衝作用。
運作連續性	高。 如果 Elsa 離線會發生什麼？員工能力的萎縮可能導致無法進行人工審查。	低。 人工流程仍是核心能力。
7. 結論
截至 2025 年底，FDA 與 Swissmedic 展示了兩條可行但截然不同的 AI 監管路徑。FDA 將自己定位為「數位先驅」，承擔開發與部署代理型 AI（Elsa 計畫）的風險，以解決數量與效率的危機。這使得 50 萬頁的申請文件得以快速處理，並順暢核准了 1,200 多項 AI 器材。

反之，Swissmedic 確立了自己作為「品質守護者」的地位，利用國際聯盟（IMDRF, WHO）來維持嚴格標準，而無需進行資本密集型的內部 AI 代理開發。

隨著產業邁向 2026 年，這兩條路徑的融合似乎不可避免。一旦類似 Elsa 的工具商品化並被證明安全，Swissmedic 很可能會採用；而 FDA 則可能會根據瑞士與歐洲監管機構倡導的「安全第一」原則，完善其代理工作流程。AI 監管時代已不再是試點計畫；它已成為運作標準。

8. 附錄

8.1 關鍵實體詞彙表 (20 項含背景)
Elsa 計畫 (Project Elsa)： FDA 於 2025 年推出的代理型 AI 工具，設計用於上市前分流、文獻回顧與案件優先排序，並需強制執行人類驗證。
AI 輔助試點 (AI-Assisted Pilot)： 於 2025 年 5 月完成的 FDA 關鍵計畫，驗證了 AI 在提交文件科學審查中的應用，特別是在跨申請的數據模式分析。
預定變更控制計畫 (PCCP)： 2024 年 FDA 指引，允許醫療器材製造商預先指定未來的演算法修改，使其能在不需重新提交 510(k) 的情況下進行更新。
510(k) 途徑： 2025 年 FDA 超過 96% 的 AI/ML 器材獲准的主要監管路徑，依賴於證明與對照器材的實質等同性。
生成式 AI 推展 (Generative AI Rollout)： FDA 的策略計畫，於 2025 年 6 月 30 日前在所有主要中心（CDER, CBER, CDRH）全面部署生成式 AI 工具。
Swissmedic AI 框架： 瑞士監管機構使用的一套 2022 年指引，引用 ICH、IMDRF 和 FDA 標準來評估提交中的 AI 元素。
IMDRF GMLP (N88)： 2025 年「優良機器學習規範」原則，專注於透明度、減少偏差與數據管理；Swissmedic 是主要貢獻者。
SwissDaMed 資料庫： Swissmedic 的集中式雲端醫療器材註冊系統，用於市場監測並確保利益相關者的透明度。
代理型 AI (Agentic AI)： 一種提供自主多步驟工作流程能力的先進 AI 形式，FDA 於 2025 年部署用於審查與行政任務，並有嚴格監督。
Martin Makary： FDA 局長（截至報告期間），宣布了 2025 年的 AI 擴展及 Elsa 計畫的啟動。
優良監管審查規範 (Good Regulatory Review Practices)： 一個 IMDRF 工作組，Swissmedic 在其中積極貢獻於定義審查 AI/ML 技術的標準。
軟體即醫療器材 (SaMD)： IMDRF 的主要關注領域，指導 Swissmedic 對獨立 AI 軟體的評估。
ICH 指引： 國際醫藥法規協和會標準（如 M10, Q9），Swissmedic 利用其來驗證藥品提交中的 AI 生成數據。
上市前核准 (PMA)： 最嚴格的 FDA 途徑，用於約 0.4% 的高風險 AI 器材（第三等級），需要臨床試驗。
De Novo 途徑： 針對無現有對照品的創新第一等級或第二等級 AI 器材的 FDA 監管路徑，佔獲准量的 ~3-4%。
RFIA 要求： 「資訊/補充要求（Request for Information/Additional）」——Swissmedic 在器材審查期間發出的查詢，通常聚焦於 AI 數據透明度。
WHO 列名監管機構 (WHO Listed Authority)： Swissmedic 的地位（2024-2025 年確認），促進了全球協調及其他國家對其決策的依賴。
AI/ML 器材清單： FDA 的公開追蹤清單，記錄了 AI 器材從 2015 年的 6 項指數增長至 2025 年中期的 1,200 多項。
全生命週期監管 (Lifecycle Supervision)： Swissmedic 的監管理念，強調 AI 產品的持續上市後監控，而非僅止於上市前許可。
偏差與透明度 (Bias and Transparency)： 雙方機構在審查 AI 模型時優先考慮的兩個核心倫理與技術挑戰，以防止病患受害。
8.2 進一步分析的追蹤問題
FDA 的 Elsa 在實務中處理 50 萬頁提交文件時，具體如何解決代幣限制（Token Limits）與上下文窗口（Context Windows）的問題？
哪些具體的量化指標（例如：審查工時的減少）顯示了 FDA 2025 年 AI 試點的成功？
比較 2024 年後透過 PCCP 獲准的 AI 器材與透過傳統 510(k) 重新提交的器材之安全性結果。
截至 2025 年底，Swissmedic 是否曾試點任何用於行政任務（人資、財務）的內部 AI 工具，即使不用于審查？
詳細說明美國與瑞士在實施 IMDRF 10 項 GMLP 原則上的具體差異。
2025 年 AI 推展適逢裁員，對 FDA 員工造成了什麼文化與士氣影響？
SwissDaMed 在技術上如何與醫院系統整合，以利用 AI 進行自動化市場監測訊號偵測？
分析 2025 年 AI 器材的 510(k) 與 PMA 核准率——對於軟體而言，PMA 途徑是否正變得過時？
FDA 審查員使用 AI 輔助工具識別並拒絕了哪些具體的演算法偏差案例？
Swissmedic 的 WHO 列名監管機構地位具體如何促進瑞士醫療器材出口至新興市場？
Elsa 計畫是否擁有對 FDA 決策資料庫的寫入權限，抑或嚴格限制為唯讀並僅具備草擬功能？
自 2022 年以來，Swissmedic 在 IMDRF AI 工作組中針對「人在迴路」要求貢獻了哪些具體條款？
FDA 對於生物製劑（CBER）審查中使用 AI 有何具體計畫，這與小分子藥物（CDER）有何不同？
「驗證」代理型 AI 輸出的技術挑戰是什麼——如何為非確定性（Nondeterministic）的輸出設定基準？
Swissmedic 如何評估用於「適應性臨床試驗設計」的 AI，其中試驗參數會根據即時數據而改變？
根據 2025 年的數據，2026 年與 2027 年 AI/ML 器材獲准的增長預測為何？
FDA 與 EMA 對「黑盒子」演算法的接受度是否有顯著差異，Swissmedic 如何在兩者之間定位？
Swissmedic 指引評估中人類監督的具體協議為何——是否存在「四眼原則（Four-eyes principle）」？
AI 對審查時程的經濟影響為何——申請費用是否下降，或上市時間是否縮短？
瑞士議會是否有立法提案，建議建立一個獨立於 Swissmedic 之外的專門「AI 與數位健康局」？
